"""
LangGraph Agent for Experiment Notes Search
å®Ÿé¨“ãƒãƒ¼ãƒˆæ¤œç´¢ç”¨ã®LangGraphã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨ãƒ¢ãƒ‡ãƒ«ã‚’å‹•çš„ã«è¨­å®šå¯èƒ½
"""
import operator
import json
import re
import time
from typing import TypedDict, List, Annotated, Optional

from langgraph.graph import StateGraph, END
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_chroma import Chroma
from langchain_core.messages import HumanMessage, BaseMessage
import cohere

from config import config
from utils import load_master_dict, normalize_text
from prompts import get_default_prompt
from chroma_sync import get_chroma_vectorstore


# --- Stateå®šç¾© ---
class AgentState(TypedDict):
    messages: Annotated[List[BaseMessage], operator.add]

    # å…¥åŠ›ãƒ‡ãƒ¼ã‚¿
    input_purpose: str
    input_materials: str
    input_methods: str

    # å‡¦ç†ãƒ‡ãƒ¼ã‚¿
    normalized_materials: str
    user_focus_instruction: str
    search_query: str

    # æ¤œç´¢çµæœ
    retrieved_docs: List[str]  # UIè¡¨ç¤ºç”¨ã®æœ€çµ‚é¸æŠœï¼ˆé€šå¸¸: Top 3ã€è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰: Top 10ï¼‰

    iteration: int
    evaluation_mode: bool  # è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰ãƒ•ãƒ©ã‚°ï¼ˆTrue: æ¯”è¼ƒçœç•¥ã€Top10è¿”å´ï¼‰


class SearchAgent:
    """æ¤œç´¢ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ»ãƒ¢ãƒ‡ãƒ«ã‚’å‹•çš„è¨­å®šå¯èƒ½ï¼‰"""

    def __init__(
        self,
        openai_api_key: str,
        cohere_api_key: str,
        embedding_model: str = None,
        llm_model: str = None,
        prompts: dict = None
    ):
        """
        Args:
            openai_api_key: OpenAI APIã‚­ãƒ¼
            cohere_api_key: Cohere APIã‚­ãƒ¼
            embedding_model: Embeddingãƒ¢ãƒ‡ãƒ«å
            llm_model: LLMãƒ¢ãƒ‡ãƒ«å
            prompts: ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¾æ›¸ {"query_generation": "...", "compare": "..."}
        """
        self.openai_api_key = openai_api_key
        self.cohere_api_key = cohere_api_key

        # ãƒ¢ãƒ‡ãƒ«è¨­å®š
        self.embedding_model = embedding_model or config.DEFAULT_EMBEDDING_MODEL
        self.llm_model = llm_model or config.DEFAULT_LLM_MODEL

        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­å®šï¼ˆã‚«ã‚¹ã‚¿ãƒ ã¾ãŸã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
        self.prompts = prompts or {}

        # Cohere ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
        self.cohere_client = cohere.Client(cohere_api_key)

        # æ­£è¦åŒ–è¾æ›¸
        self.norm_map, _ = load_master_dict()

        # Embeddingé–¢æ•°
        self.embedding_function = OpenAIEmbeddings(
            model=self.embedding_model,
            api_key=self.openai_api_key
        )

        # Vector Storeï¼ˆGCSåŒæœŸä»˜ãï¼‰
        self.vectorstore = get_chroma_vectorstore(self.embedding_function)

        # LLM
        self.llm = ChatOpenAI(
            model=self.llm_model,
            temperature=0,
            api_key=self.openai_api_key
        )

        # ã‚°ãƒ©ãƒ•ã‚’æ§‹ç¯‰
        self.graph = self._build_graph()

    def _get_prompt(self, prompt_type: str) -> str:
        """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—ï¼ˆã‚«ã‚¹ã‚¿ãƒ ã¾ãŸã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰"""
        return self.prompts.get(prompt_type, get_default_prompt(prompt_type))

    def _normalize_node(self, state: AgentState):
        """æ­£è¦åŒ–ãƒãƒ¼ãƒ‰"""
        start_time = time.time()
        evaluation_mode = state.get("evaluation_mode", False)

        if evaluation_mode:
            print("\n" + "="*80)
            print("ğŸ”¬ [è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰] æ€§èƒ½è©•ä¾¡å®Ÿè¡Œä¸­")
            print("="*80)
            print("\n--- ğŸš€ [1/3] æ­£è¦åŒ– & JSONè§£æ ---")
        else:
            print("\n--- ğŸš€ [1/4] æ­£è¦åŒ– & JSONè§£æ ---")

        updates = {}
        messages = state.get("messages", [])

        # JSONè§£æ
        if messages:
            last_msg = messages[-1]
            content = ""
            if hasattr(last_msg, "content"):
                content = last_msg.content
            elif isinstance(last_msg, dict):
                content = last_msg.get("content", "")
            else:
                content = str(last_msg)

            if content.strip().startswith("{"):
                try:
                    data = json.loads(content)

                    if data.get("type") == "initial_search":
                        updates["input_purpose"] = data.get("purpose", "")
                        updates["input_materials"] = data.get("materials", "")
                        updates["input_methods"] = data.get("methods", "")

                        # åˆå›æ¤œç´¢æ™‚ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæŒ‡ç¤º
                        updates["user_focus_instruction"] = (
                            "ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹ææ–™(åŒ–å­¦ç‰©è³ªã€å®¹é‡ï¼‰ã¨ã€æ–¹æ³•ï¼ˆåŒ–å­¦ç‰©è³ªã€å®¹é‡ã€æ‰‹é †ï¼‰ã®è¨˜è¿°ãŒ"
                            "é¡ä¼¼ã—ã¦ã„ã‚‹å®Ÿé¨“ãƒãƒ¼ãƒˆã‚’æœ€å„ªå…ˆã—ã¦æ¤œç´¢ã—ã¦ãã ã•ã„ã€‚"
                        )

                    elif data.get("type") == "refinement":
                        updates["user_focus_instruction"] = data.get("instruction", "")
                        updates["input_purpose"] = data.get("purpose", "")
                        updates["input_materials"] = data.get("materials", "")
                        updates["input_methods"] = data.get("methods", "")

                except json.JSONDecodeError:
                    print("  > âš ï¸ JSON Decode Error")

        # æ­£è¦åŒ–å‡¦ç†
        raw_materials = updates.get("input_materials", state.get("input_materials", ""))
        normalized_parts = []

        if raw_materials:
            lines = raw_materials.split('\n')
            for line in lines:
                line = line.strip()
                if not line:
                    continue
                parts = re.split(r'[:ï¼š]', line, 1)

                if len(parts) == 2:
                    left_part = parts[0]
                    amount_part = parts[1]
                    raw_name = re.sub(r'^[-ãƒ»\s]*[â‘ -â‘¨0-9.]*\s*', '', left_part).strip()
                    norm_name = normalize_text(raw_name, self.norm_map)
                    normalized_parts.append(f"- {norm_name}: {amount_part.strip()}")
                else:
                    clean_line = re.sub(r'^[-ãƒ»\s]*[â‘ -â‘¨0-9.]*\s*', '', line).strip()
                    norm_name = normalize_text(clean_line, self.norm_map)
                    normalized_parts.append(norm_name)

        normalized_str = "\n".join(normalized_parts) if normalized_parts else raw_materials
        updates["normalized_materials"] = normalized_str

        # è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰æ™‚ã«å…¥åŠ›æƒ…å ±ã‚’è©³ç´°è¡¨ç¤º
        if evaluation_mode:
            print("\n  ğŸ“‹ [å…¥åŠ›æƒ…å ±]")
            print(f"  ç›®çš„: {updates.get('input_purpose', state.get('input_purpose', ''))}")
            print(f"  ææ–™: {updates.get('input_materials', state.get('input_materials', ''))}")
            print(f"  å®Ÿé¨“æ‰‹æ³•: {updates.get('input_methods', state.get('input_methods', ''))}")
            print(f"  é‡ç‚¹æŒ‡ç¤º: {updates.get('user_focus_instruction', state.get('user_focus_instruction', ''))}")
            print(f"\n  ğŸ“ [æ­£è¦åŒ–å¾Œã®ææ–™]")
            print(f"  {normalized_str}")

        elapsed_time = time.time() - start_time
        print(f"  â±ï¸ Execution Time: {elapsed_time:.4f} sec")
        return updates

    def _generate_query_node(self, state: AgentState):
        """ã‚¯ã‚¨ãƒªç”Ÿæˆãƒãƒ¼ãƒ‰"""
        start_time = time.time()
        evaluation_mode = state.get("evaluation_mode", False)

        if evaluation_mode:
            print("\n--- ğŸ§  [2/3] å¤šè§’çš„æ¤œç´¢ã‚¯ã‚¨ãƒªç”Ÿæˆ ---")
        else:
            print("--- ğŸ§  [2/4] å¤šè§’çš„æ¤œç´¢ã‚¯ã‚¨ãƒªç”Ÿæˆ ---")

        instruction = state.get('user_focus_instruction', 'ç‰¹ã«ãªã—')

        # ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¾ãŸã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—
        prompt_template = self._get_prompt("query_generation")

        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å¤‰æ•°ã‚’åŸ‹ã‚è¾¼ã‚€
        prompt = prompt_template.format(
            input_purpose=state.get('input_purpose'),
            normalized_materials=state.get('normalized_materials'),
            input_methods=state.get('input_methods'),
            user_focus_instruction=instruction
        )

        response = self.llm.invoke(prompt)

        content = response.content.strip()
        if content.startswith("```json"):
            content = content.replace("```json", "").replace("```", "").strip()

        try:
            data = json.loads(content)
            queries = data.get("queries", [])
            if not queries:
                raise ValueError("Empty queries")

            combined_query = " ".join(queries)

            # è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰æ™‚ã¯ã‚¯ã‚¨ãƒªå…¨ä½“ã‚’è¡¨ç¤º
            if evaluation_mode:
                print(f"\n  ğŸ” [ç”Ÿæˆã•ã‚ŒãŸã‚¯ã‚¨ãƒª]")
                print(f"  çµ±åˆã‚¯ã‚¨ãƒªï¼ˆ{len(queries)}å€‹ã®ã‚¯ã‚¨ãƒªã‚’çµåˆï¼‰:")
                print(f"  {combined_query}")
                print(f"\n  å„ã‚¯ã‚¨ãƒªã®è©³ç´°:")
                for i, q in enumerate(queries, 1):
                    print(f"    {i}. {q}")
            else:
                print(f"  > Generated Query: {combined_query[:100]}...")

        except Exception as e:
            print(f"  > âš ï¸ Query Parse Error: {e}")
            combined_query = f"{state.get('input_purpose')} {state.get('normalized_materials')} {instruction}"

        elapsed_time = time.time() - start_time
        print(f"  â±ï¸ Execution Time: {elapsed_time:.4f} sec")
        return {"search_query": combined_query}

    def _search_node(self, state: AgentState):
        """æ¤œç´¢ & Cohereãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒãƒ¼ãƒ‰"""
        start_time = time.time()
        evaluation_mode = state.get("evaluation_mode", False)

        if evaluation_mode:
            print("--- ğŸ” [3/3] æ¤œç´¢ & Cohereãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°å®Ÿè¡Œï¼ˆè©•ä¾¡ãƒ¢ãƒ¼ãƒ‰ï¼‰---")
        else:
            print("--- ğŸ” [3/4] æ¤œç´¢ & Cohereãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°å®Ÿè¡Œ ---")

        query = state["search_query"]

        try:
            # ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢
            candidates = self.vectorstore.similarity_search(query, k=config.VECTOR_SEARCH_K)

            if not candidates:
                print("  > No candidates found in vector search.")
                print(f"  â±ï¸ Execution Time: {time.time() - start_time:.4f} sec")
                return {"retrieved_docs": [], "iteration": state.get("iteration", 0) + 1}

            print(f"  > Vector Search: Retrieved {len(candidates)} candidates.")

            # Cohere Rerank
            documents_content = [doc.page_content for doc in candidates]

            rerank_results = self.cohere_client.rerank(
                model=config.DEFAULT_RERANK_MODEL,
                query=query,
                documents=documents_content,
                top_n=config.RERANK_TOP_N
            )

            if evaluation_mode:
                print(f"\n  ğŸ“Š [ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°çµæœ] Top {config.RERANK_TOP_N} ä»¶")
                print(f"  " + "="*76)
            else:
                print(f"\n  ğŸ“Š [Console Log] Top {config.RERANK_TOP_N} Cohere Rerank Results:")
                print(f"  --------------------------------------------------")

            docs_for_ui = []

            # è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰ãªã‚‰å…¨ä»¶ï¼ˆTop10ï¼‰ã€é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ãªã‚‰ä¸Šä½3ä»¶ã®ã¿
            display_limit = config.RERANK_TOP_N if evaluation_mode else config.UI_DISPLAY_TOP_N

            for i, result in enumerate(rerank_results.results):
                original_doc = candidates[result.index]
                source_id = original_doc.metadata.get('source', 'unknown')
                score = result.relevance_score
                snippet = original_doc.page_content[:50].replace('\n', ' ')

                if evaluation_mode:
                    print(f"  Rank {i+1:2d} | Score: {score:.6f} | ãƒãƒ¼ãƒˆID: {source_id}")
                else:
                    print(f"  Rank {i+1:2d} | Score: {score:.4f} | ID: {source_id} | {snippet}...")

                # è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰ãªã‚‰å…¨ä»¶ã€é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ãªã‚‰ä¸Šä½3ä»¶ã®ã¿ä¿å­˜
                if i < display_limit:
                    docs_for_ui.append(f"ã€å®Ÿé¨“ãƒãƒ¼ãƒˆID: {source_id}ã€‘\n{original_doc.page_content}")

            if evaluation_mode:
                print(f"  " + "="*76)
                print(f"  âœ… è©•ä¾¡ç”¨ã«ä¸Šä½ {len(docs_for_ui)} ä»¶ã‚’è¿”å´ã—ã¾ã™ã€‚")
            else:
                print(f"  --------------------------------------------------")
                print(f"  > UIå‘ã‘ã«ä¸Šä½ {len(docs_for_ui)} ä»¶ã‚’é¸æŠã—ã¾ã—ãŸã€‚")

        except Exception as e:
            print(f"  > âš ï¸ Search/Rerank Error: {e}")
            docs_for_ui = []

        elapsed_time = time.time() - start_time
        print(f"  â±ï¸ Execution Time: {elapsed_time:.4f} sec")

        # è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰æ™‚ã¯çµ‚äº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
        if evaluation_mode:
            print("\n" + "="*80)
            print("âœ… è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰çµ‚äº† - æ¯”è¼ƒãƒãƒ¼ãƒ‰ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦çµæœã‚’è¿”å´ã—ã¾ã™")
            print("="*80 + "\n")

        return {
            "retrieved_docs": docs_for_ui,
            "iteration": state.get("iteration", 0) + 1
        }

    def _compare_node(self, state: AgentState):
        """æ¯”è¼ƒãƒ»è¦ç´„ç”Ÿæˆãƒãƒ¼ãƒ‰"""
        start_time = time.time()
        print("--- ğŸ“ [4/4] æ¯”è¼ƒãƒ»è¦ç´„ç”Ÿæˆ (Deep Analysis) ---")

        input_purpose = state.get('input_purpose')
        input_materials = state.get('normalized_materials')
        input_methods = state.get('input_methods')
        instruction = state.get('user_focus_instruction', '')

        docs_str = "\n\n".join(state.get("retrieved_docs", []))

        if not docs_str:
            print(f"  â±ï¸ Execution Time: {time.time() - start_time:.4f} sec")
            return {"messages": [HumanMessage(content="è©²å½“ã™ã‚‹ãƒãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")]}

        # ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¾ãŸã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—
        prompt_template = self._get_prompt("compare")

        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å¤‰æ•°ã‚’åŸ‹ã‚è¾¼ã‚€
        prompt = prompt_template.format(
            input_purpose=input_purpose,
            normalized_materials=input_materials,
            input_methods=input_methods,
            user_focus_instruction=instruction,
            retrieved_docs=docs_str
        )

        response = self.llm.invoke(prompt)

        elapsed_time = time.time() - start_time
        print(f"  â±ï¸ Execution Time: {elapsed_time:.4f} sec")
        return {"messages": [response]}

    def _should_compare(self, state: AgentState):
        """compareãƒãƒ¼ãƒ‰ã«é€²ã‚€ã¹ãã‹ã‚’åˆ¤å®š"""
        evaluation_mode = state.get("evaluation_mode", False)
        if evaluation_mode:
            return END
        else:
            return "compare"

    def _build_graph(self):
        """ã‚°ãƒ©ãƒ•ã‚’æ§‹ç¯‰"""
        workflow = StateGraph(AgentState)

        workflow.add_node("normalize", self._normalize_node)
        workflow.add_node("generate_query", self._generate_query_node)
        workflow.add_node("search", self._search_node)
        workflow.add_node("compare", self._compare_node)

        workflow.set_entry_point("normalize")
        workflow.add_edge("normalize", "generate_query")
        workflow.add_edge("generate_query", "search")

        # è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰ãªã‚‰compareã‚’ã‚¹ã‚­ãƒƒãƒ—
        workflow.add_conditional_edges(
            "search",
            self._should_compare,
            {
                "compare": "compare",
                END: END
            }
        )
        workflow.add_edge("compare", END)

        return workflow.compile()

    def run(self, input_data: dict, evaluation_mode: bool = False):
        """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å®Ÿè¡Œ

        Args:
            input_data: æ¤œç´¢æ¡ä»¶ï¼ˆpurpose, materials, methodsç­‰ï¼‰
            evaluation_mode: è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰ï¼ˆTrue: æ¯”è¼ƒçœç•¥ã€Top10è¿”å´ã€False: é€šå¸¸å‹•ä½œï¼‰
        """
        initial_state = {
            "messages": [HumanMessage(content=json.dumps(input_data, ensure_ascii=False))],
            "input_purpose": "",
            "input_materials": "",
            "input_methods": "",
            "normalized_materials": "",
            "user_focus_instruction": "",
            "search_query": "",
            "retrieved_docs": [],
            "iteration": 0,
            "evaluation_mode": evaluation_mode
        }

        result = self.graph.invoke(initial_state)
        return result
